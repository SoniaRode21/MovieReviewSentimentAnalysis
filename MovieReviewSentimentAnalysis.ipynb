{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following code uses movie_reviews data from nltk.corpus. The data contains files with movie reviews and \n",
    "their corresponding labels(positive or negative)\n",
    "It does text preprocessing such as removing stop words and tokenization.\n",
    "After preprocessing different classifiers like Naive Bayesian classifier,SVC_classifier,BernoulliNB_classifier,\n",
    "SGDClassifier_classifier,LogisticRegression_classifier are implemented.\n",
    "Finally a aggregator classifer which outputs the most voted label and its confidence is implemented.\n",
    "\n",
    "\n",
    "__author__='Soniya Rode'\n",
    "__citation__=\"pythonprogramming\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initalise the stop words set and tokenizer to remove punctuations.\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all words in the movie reviews\n",
    "words = []\n",
    "\n",
    "for w in movie_reviews.words():\n",
    "    #If the word is not a punctuation mark and not in stopwords add it to the list\n",
    "    if tokenizer.tokenize(w) and w not in stopwords:\n",
    "        words.append(w.lower())\n",
    "        #print(words)\n",
    "    \n",
    "\n",
    "#Get frequencies of all words\n",
    "words = nltk.FreqDist(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get top most 10 common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('film', 9517),\n",
       " ('one', 5852),\n",
       " ('movie', 5771),\n",
       " ('like', 3690),\n",
       " ('even', 2565),\n",
       " ('good', 2411),\n",
       " ('time', 2411),\n",
       " ('story', 2169),\n",
       " ('would', 2109),\n",
       " ('much', 2049)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the top 4000 common words\n",
    "commonWords=list(words.keys())[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are two categories pos,neg\n",
    "#for every category, get the files associated with it.\n",
    "# Add the review words, the category as a tuple to the reviews\n",
    "reviews = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "#Shuffle the data since arranged categorywise\n",
    "#reviews variable contains all reviews with their labels\n",
    "random.shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to return boolean value for words from the review which are amongst the most common words.\n",
    "#Return True if the word in the review is among the top 4000 words.\n",
    "def check_commonWords(words):\n",
    "    words = set(words)\n",
    "    listOfCommonWords = {}\n",
    "    for w in commonWords:\n",
    "        listOfCommonWords[w] = (w in words)\n",
    "\n",
    "    return listOfCommonWords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now\n",
    "featuresets = [(check_commonWords(rev), category) for (rev, category) in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(featuresets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing\n",
    "training_set = featuresets[:1800]\n",
    "\n",
    "# set that we'll test against.\n",
    "testing_set = featuresets[1800:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use NLTK's Naive Bayes classifier \n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 80.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"accuracy:\",(nltk.classify.accuracy(classifier, testing_set))*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                bothered = True              neg : pos    =      8.9 : 1.0\n",
      "                 miscast = True              neg : pos    =      8.1 : 1.0\n",
      "                 frances = True              pos : neg    =      7.7 : 1.0\n",
      "                sundance = True              pos : neg    =      7.7 : 1.0\n",
      "              schumacher = True              neg : pos    =      7.4 : 1.0\n",
      "           unimaginative = True              neg : pos    =      7.0 : 1.0\n",
      "                  shoddy = True              neg : pos    =      7.0 : 1.0\n",
      "               atrocious = True              neg : pos    =      7.0 : 1.0\n",
      "                jeopardy = True              neg : pos    =      6.3 : 1.0\n",
      "                  suvari = True              neg : pos    =      6.3 : 1.0\n",
      "                    mena = True              neg : pos    =      6.3 : 1.0\n",
      "                  wasted = True              neg : pos    =      5.7 : 1.0\n",
      "                 singers = True              pos : neg    =      5.7 : 1.0\n",
      "                 bronson = True              neg : pos    =      5.6 : 1.0\n",
      "               underwood = True              neg : pos    =      5.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the classifier\n",
    "Pickle_classifier = open(\"naivebayes.pickle\",\"wb\")\n",
    "pickle.dump(classifier, Pickle_classifier)\n",
    "Pickle_classifier.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using sklearn classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression Classifier\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression(solver='lbfgs'))\n",
    "LogisticRegression_classifier.train(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stochastic gradient descent (SGD) classifier\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier( max_iter=1000))\n",
    "SGDClassifier_classifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support Vector machine Classifier\n",
    "SVC_classifier = SklearnClassifier(SVC(gamma='auto'))\n",
    "SVC_classifier.train(training_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB_classifier accuracy percent: 81.0\n"
     ]
    }
   ],
   "source": [
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracies :\n",
      "Naive Bayes Classifier accuracy: 80.5\n",
      "LogisticRegression_classifier accuracy: 78.5\n",
      "SGDClassifier_classifier accuracy: 80.0\n",
      "SVC_classifier accuracy: 80.0\n"
     ]
    }
   ],
   "source": [
    "#Classifier Accuracies:\n",
    "print(\"Classifier accuracies :\")\n",
    "print(\"Naive Bayes Classifier accuracy:\",(nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "print(\"LogisticRegression_classifier accuracy:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "print(\"SGDClassifier_classifier accuracy:\", (nltk.classify.accuracy(SGDClassifier_classifier, testing_set))*100)\n",
    "print(\"SVC_classifier accuracy:\", (nltk.classify.accuracy(SVC_classifier, testing_set))*100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aggregated Classifier takes different classifiers as input. To classify it takes vote from each classifier, and \n",
    "returns the class label with most number of votes(mode)\n",
    "The get_confidence method returns the confidence on the vote(class label)\n",
    "\n",
    "The get_confidence uses mode method from statistics which raisies statistics.StatisticsError\n",
    "statistics.StatisticsError: no unique mode; found 2 equally common values \n",
    "Since number of classifiers used in uneven, this error is avoided.\n",
    "'''\n",
    "class AggregatedClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    def classify(self, features):\n",
    "            votes = []\n",
    "            for classifier in self._classifiers:\n",
    "                votes.append(classifier.classify(features))\n",
    "            return mode(votes)\n",
    "    def get_confidence(self, features):\n",
    "        votes = []\n",
    "        for classifier in self._classifiers:\n",
    "            votes.append(classifier.classify(features))\n",
    "\n",
    "         \n",
    "        confidence = votes.count(mode(votes)) / len(votes)\n",
    "        return confidence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class label: pos Confidence %: 100.0\n",
      "Predicted Class label: neg Confidence %: 80.0\n",
      "Predicted Class label: neg Confidence %: 100.0\n",
      "Predicted Class label: pos Confidence %: 80.0\n",
      "Predicted Class label: neg Confidence %: 80.0\n",
      "Predicted Class label: neg Confidence %: 100.0\n",
      "Predicted Class label: neg Confidence %: 100.0\n",
      "Predicted Class label: neg Confidence %: 100.0\n",
      "Predicted Class label: neg Confidence %: 60.0\n",
      "Predicted Class label: neg Confidence %: 80.0\n",
      "Predicted Class label: neg Confidence %: 100.0\n",
      "Predicted Class label: pos Confidence %: 100.0\n",
      "Predicted Class label: pos Confidence %: 100.0\n",
      "Predicted Class label: neg Confidence %: 100.0\n",
      "Predicted Class label: pos Confidence %: 100.0\n",
      "Predicted Class label: neg Confidence %: 60.0\n",
      "Predicted Class label: neg Confidence %: 100.0\n",
      "Predicted Class label: neg Confidence %: 100.0\n",
      "Predicted Class label: neg Confidence %: 60.0\n",
      "Predicted Class label: neg Confidence %: 80.0\n"
     ]
    }
   ],
   "source": [
    "agg_classifier = AggregatedClassifier(classifier,SVC_classifier,BernoulliNB_classifier,SGDClassifier_classifier,LogisticRegression_classifier)\n",
    "\n",
    "#print(\"voted_classifier accuracy percent:\", (nltk.classify.accuracy(voted_classifier, testing_set))*100)\n",
    "for i in range(20):\n",
    "    print(\"Predicted Class label:\", agg_classifier.classify(testing_set[i][0]), \"Confidence %:\",agg_classifier.get_confidence(testing_set[i][0])*100)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
